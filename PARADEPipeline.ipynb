{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading terrier-assemblies 5.x-SNAPSHOT  jar-with-dependencies to /root/.pyterrier...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init(version=\"snapshot\")\n",
    "    \n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "from pyterrier.transformer import TransformerBase\n",
    "\n",
    "from run_reranking import model_fn_builder\n",
    "from input_parser import input_fn_builder\n",
    "from bert.modeling import BertConfig\n",
    "from generate_data import PointwiseInstance\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_instance_pointwise(tokenizer, max_seq_length, qid, docno, query, doc, label):\n",
    "  query = tokenization.convert_to_unicode(query)\n",
    "  doc = tokenization.convert_to_unicode(doc)\n",
    "  passages = get_passages(doc, 150, 50)\n",
    "  if len(passages) == 0:\n",
    "    tf.logging.warn(\"Passage length is 0 in qid {} docno {}\".format(qid, docno))\n",
    "\n",
    "  query = tokenization.convert_to_bert_input(\n",
    "    text=query,\n",
    "    max_seq_length=64,\n",
    "    tokenizer=tokenizer,\n",
    "    add_cls=True,\n",
    "    convert_to_id=False\n",
    "  )\n",
    "  passages = [tokenization.convert_to_bert_input(\n",
    "    text=p,\n",
    "    max_seq_length=max_seq_length-len(query),\n",
    "    tokenizer=tokenizer,\n",
    "    add_cls=False,\n",
    "    convert_to_id=False\n",
    "  ) for p in passages]\n",
    "  instance = PointwiseInstance(\n",
    "    exampleid=\"{}-{}\".format(qid, docno),\n",
    "    tokens_a=query,\n",
    "    tokens_b_list=passages,\n",
    "    relation_label=label\n",
    "  )\n",
    "\n",
    "  return instance\n",
    "\n",
    "def get_passages(text, plen, overlap):\n",
    "    \"\"\" Modified from https://github.com/AdeDZY/SIGIR19-BERT-IR/blob/master/tools/gen_passages.py\n",
    "    :param text:\n",
    "    :param plen:\n",
    "    :param overlap:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    words = text.strip().split(' ')\n",
    "    s, e = 0, 0\n",
    "    passages = []\n",
    "    while s < len(words):\n",
    "      e = s + plen\n",
    "      if e >= len(words):\n",
    "        e = len(words)\n",
    "      # if the last one is shorter than 'overlap', it is already in the previous passage.\n",
    "      if len(passages) > 0 and e - s <= overlap:\n",
    "        break\n",
    "      p = ' '.join(words[s:e])\n",
    "      passages.append(p)\n",
    "      s = s + plen - overlap\n",
    "\n",
    "    if len(passages) > 8:\n",
    "      chosen_ids = sorted(random.sample(range(1, len(passages) - 1), 8 - 2))\n",
    "      chosen_ids = [0] + chosen_ids + [len(passages) - 1]\n",
    "      passages = [passages[id] for id in chosen_ids]\n",
    "\n",
    "    return passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_data import create_int_feature\n",
    "\n",
    "def convert_tokens_to_ids(vocab, tokens):\n",
    "    return [vocab[token] for token in tokens]\n",
    "\n",
    "def write_instance_to_example_files(writer, tokenizer, instance, instance_idx):\n",
    "    \n",
    "    def padding_2d(ids_list, num_tokens_per_segment, padding_value=0):\n",
    "        _len = len(ids_list)\n",
    "        if padding_value == 0:\n",
    "            matrix = np.zeros((_len, num_tokens_per_segment), dtype=np.int)\n",
    "        elif padding_value == 1:\n",
    "            matrix = np.ones((_len, num_tokens_per_segment), dtype=np.int)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupport padding value\")\n",
    "\n",
    "        for i, _list in enumerate(ids_list):\n",
    "            matrix[i, :len(_list)] = _list\n",
    "\n",
    "        return matrix.flatten()\n",
    "\n",
    "    tokens_a = instance.tokens_a\n",
    "    tokens_b_list = instance.tokens_b_list\n",
    "    tokens_a_ids = convert_tokens_to_ids(tokenizer.vocab, tokens_a)\n",
    "    tokens_b_list = [convert_tokens_to_ids(tokenizer.vocab, p) for p in tokens_b_list]\n",
    "    label = instance.relation_label\n",
    "    assert len(tokens_b_list) <= 8\n",
    "    num_segments = len(tokens_b_list)\n",
    "\n",
    "    input_ids = [tokens_a_ids + tokens_b_passage_ids for tokens_b_passage_ids in tokens_b_list]\n",
    "    tokens_a_len = len(tokens_a_ids)  # helpful for segment ids\n",
    "    input_ids_lens = [len(input_id) for input_id in input_ids]  # helpful for input mask\n",
    "    input_ids_lens = input_ids_lens + [128] * (8 - len(input_ids_lens))\n",
    "    input_ids = padding_2d(input_ids, 128, padding_value=0)\n",
    "    # write to tfrecord\n",
    "    features = collections.OrderedDict()\n",
    "    features[\"input_ids\"] = create_int_feature(input_ids)\n",
    "    features[\"tokens_a_len\"] = create_int_feature([tokens_a_len])\n",
    "    features[\"tokens_ids_lens\"] = create_int_feature(input_ids_lens)\n",
    "    features[\"num_segments\"] = create_int_feature([num_segments])\n",
    "    features[\"label\"] = create_int_feature([label])\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "    \n",
    "    if instance_idx < 5:\n",
    "        tf.logging.info(\"*** Example ***\")\n",
    "        tf.logging.info(\"tokens_a: %s\" % \" \".join(\n",
    "            [tokenization.printable_text(x) for x in instance.tokens_a]))\n",
    "        tf.logging.info(\"tokens_b_list: {}\".format(instance.tokens_b_list))\n",
    "\n",
    "        for feature_name in features.keys():\n",
    "            feature = features[feature_name]\n",
    "            values = []\n",
    "            if feature.int64_list.value:\n",
    "                values = feature.int64_list.value\n",
    "            elif feature.float_list.value:\n",
    "                values = feature.float_list.value\n",
    "            tf.logging.info(\n",
    "                \"%s: %s\" % (feature_name, \" \".join([str(x) for x in values])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_feature_list(df, tokenizer, writer):\n",
    "    feature_list = []\n",
    "    for ind, line in enumerate(df.itertuples()):\n",
    "        instance = create_instance_pointwise(\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_seq_length=512,\n",
    "                            qid=line.qid,\n",
    "                            docno=line.docno,\n",
    "                            query=line.query,\n",
    "                            doc=line.body,\n",
    "                            label=0\n",
    "        )\n",
    "        \n",
    "        write_instance_to_example_files(writer, tokenizer, instance, ind)\n",
    "\n",
    "        \n",
    "class PARADEPipeline(TransformerBase):\n",
    "    def __init__(self, aggregation_method):\n",
    "        self.aggregation_method = aggregation_method #'cls_max',  'cls_avg', 'cls_attn' or 'cls_transformer'\n",
    "\n",
    "        self.tokenizer = tokenization.FullTokenizer(vocab_file='vocab.txt')\n",
    "        self.writer = tf.python_io.TFRecordWriter(\"output.tfrecords\")\n",
    "\n",
    "        self.run_config = tf.estimator.tpu.RunConfig(\n",
    "            cluster=None,\n",
    "            model_dir=None,\n",
    "            save_checkpoints_steps=1000,\n",
    "            keep_checkpoint_max=1,\n",
    "            tpu_config=tf.estimator.tpu.TPUConfig(\n",
    "                iterations_per_loop=1000,\n",
    "                num_shards=8,\n",
    "                per_host_input_for_training=tf.estimator.tpu.InputPipelineConfig.PER_HOST_V2))\n",
    "\n",
    "        self.model_fn = model_fn_builder(\n",
    "            bert_config=BertConfig.from_json_file('bert_models_onMSMARCO/vanilla_bert_tiny_on_MSMARCO/bert_config.json'),\n",
    "            num_labels=2,\n",
    "            init_checkpoint='bert_models_onMSMARCO/vanilla_bert_tiny_on_MSMARCO/model.ckpt-1600000',\n",
    "            learning_rate=5e-5,\n",
    "            num_train_steps=None,\n",
    "            num_warmup_steps=None,\n",
    "            use_tpu=False,\n",
    "            use_one_hot_embeddings=False,\n",
    "            aggregation_method=self.aggregation_method,\n",
    "            pretrained_model='bert',\n",
    "            from_distilled_student=False)\n",
    "\n",
    "        self.estimator = tf.estimator.tpu.TPUEstimator(\n",
    "            use_tpu=False,\n",
    "            model_fn=self.model_fn,\n",
    "            config=self.run_config,\n",
    "            train_batch_size=32,\n",
    "            eval_batch_size=32,\n",
    "            predict_batch_size=32)\n",
    "        \n",
    "        \n",
    "    def transform(self, queries_and_docs):\n",
    "        def main(_):\n",
    "            df_to_feature_list(queries_and_docs, self.tokenizer, self.writer) #writes the dataframe to the filepath specified in the writer declaration\n",
    "\n",
    "            eval_input_fn = input_fn_builder(\n",
    "                dataset_path=\"output.tfrecords\",\n",
    "                max_num_segments_perdoc=8,\n",
    "                max_seq_length=128,\n",
    "                is_training=False)\n",
    "        \n",
    "            result = self.estimator.predict(input_fn=eval_input_fn, yield_single_examples=True)\n",
    "            %tb\n",
    "        \n",
    "        tf.app.run(main=main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>docno</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q1</td>\n",
       "      <td>chemical reactions</td>\n",
       "      <td>doc1</td>\n",
       "      <td>professor proton demonstrated the chemical rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid               query docno  \\\n",
       "0  q1  chemical reactions  doc1   \n",
       "\n",
       "                                                body  \n",
       "0  professor proton demonstrated the chemical rea...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "q = \"chemical reactions\"\n",
    "doc1 = \"professor proton demonstrated the chemical reaction\"\n",
    "doc2 = \"chemical brothers is great techno music\"\n",
    "\n",
    "df = pd.DataFrame([[\"q1\", q, \"doc1\", doc1]], columns=[\"qid\", \"query\", \"docno\", \"body\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fb30909dc80>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1129 13:46:03.925035 140409438652224 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fb30909dc80>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp89te4bjm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1129 13:46:03.929947 140409438652224 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp89te4bjm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp89te4bjm', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb2a605b9b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1129 13:46:03.933172 140409438652224 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp89te4bjm', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb2a605b9b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1129 13:46:03.943279 140409438652224 tpu_context.py:220] _TPUContext: eval_on_tpu True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1129 13:46:03.945817 140409438652224 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1129 13:46:03.950016 140409438652224 <ipython-input-3-0d59b4ed846a>:46] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens_a: [CLS] chemical reactions [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1129 13:46:03.952166 140409438652224 <ipython-input-3-0d59b4ed846a>:48] tokens_a: [CLS] chemical reactions [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens_b_list: [['professor', 'proton', 'demonstrated', 'the', 'chemical', 'reaction', '[SEP]']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1129 13:46:03.954101 140409438652224 <ipython-input-3-0d59b4ed846a>:49] tokens_b_list: [['professor', 'proton', 'demonstrated', 'the', 'chemical', 'reaction', '[SEP]']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5072 9597 102 2934 20843 7645 1996 5072 4668 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1129 13:46:03.956517 140409438652224 <ipython-input-3-0d59b4ed846a>:59] input_ids: 101 5072 9597 102 2934 20843 7645 1996 5072 4668 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens_a_len: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1129 13:46:03.961026 140409438652224 <ipython-input-3-0d59b4ed846a>:59] tokens_a_len: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens_ids_lens: 11 128 128 128 128 128 128 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1129 13:46:03.967952 140409438652224 <ipython-input-3-0d59b4ed846a>:59] tokens_ids_lens: 11 128 128 128 128 128 128 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:num_segments: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1129 13:46:03.988034 140409438652224 <ipython-input-3-0d59b4ed846a>:59] num_segments: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1129 13:46:03.991078 140409438652224 <ipython-input-3-0d59b4ed846a>:59] label: 0\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4cc35d8e44db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyterrier/transformer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rshift__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-5ce598d83ecb>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, queries_and_docs)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myield_single_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: "
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "pipeline = PARADEPipeline(aggregation_method='cls_max')\n",
    "\n",
    "#vaswani  = pt.datasets.get_dataset(\"vaswani\")\n",
    "#vaswani.get_corpus()\n",
    "\n",
    "\n",
    "pipeline(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
